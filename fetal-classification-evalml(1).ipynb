{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import f1_score\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.model_selection import train_test_split","metadata":{},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/fetal-health-classification/fetal_health.csv\" , sep = \",\")\ndf.head()","metadata":{"scrolled":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>baseline value</th>\n","      <th>accelerations</th>\n","      <th>fetal_movement</th>\n","      <th>uterine_contractions</th>\n","      <th>light_decelerations</th>\n","      <th>severe_decelerations</th>\n","      <th>prolongued_decelerations</th>\n","      <th>abnormal_short_term_variability</th>\n","      <th>mean_value_of_short_term_variability</th>\n","      <th>percentage_of_time_with_abnormal_long_term_variability</th>\n","      <th>...</th>\n","      <th>histogram_min</th>\n","      <th>histogram_max</th>\n","      <th>histogram_number_of_peaks</th>\n","      <th>histogram_number_of_zeroes</th>\n","      <th>histogram_mode</th>\n","      <th>histogram_mean</th>\n","      <th>histogram_median</th>\n","      <th>histogram_variance</th>\n","      <th>histogram_tendency</th>\n","      <th>fetal_health</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>120.0</td>\n","      <td>0.000</td>\n","      <td>0.0</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>73.0</td>\n","      <td>0.5</td>\n","      <td>43.0</td>\n","      <td>...</td>\n","      <td>62.0</td>\n","      <td>126.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>120.0</td>\n","      <td>137.0</td>\n","      <td>121.0</td>\n","      <td>73.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>132.0</td>\n","      <td>0.006</td>\n","      <td>0.0</td>\n","      <td>0.006</td>\n","      <td>0.003</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>17.0</td>\n","      <td>2.1</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>68.0</td>\n","      <td>198.0</td>\n","      <td>6.0</td>\n","      <td>1.0</td>\n","      <td>141.0</td>\n","      <td>136.0</td>\n","      <td>140.0</td>\n","      <td>12.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>133.0</td>\n","      <td>0.003</td>\n","      <td>0.0</td>\n","      <td>0.008</td>\n","      <td>0.003</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>16.0</td>\n","      <td>2.1</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>68.0</td>\n","      <td>198.0</td>\n","      <td>5.0</td>\n","      <td>1.0</td>\n","      <td>141.0</td>\n","      <td>135.0</td>\n","      <td>138.0</td>\n","      <td>13.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>134.0</td>\n","      <td>0.003</td>\n","      <td>0.0</td>\n","      <td>0.008</td>\n","      <td>0.003</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>16.0</td>\n","      <td>2.4</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>53.0</td>\n","      <td>170.0</td>\n","      <td>11.0</td>\n","      <td>0.0</td>\n","      <td>137.0</td>\n","      <td>134.0</td>\n","      <td>137.0</td>\n","      <td>13.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>132.0</td>\n","      <td>0.007</td>\n","      <td>0.0</td>\n","      <td>0.008</td>\n","      <td>0.000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>16.0</td>\n","      <td>2.4</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>53.0</td>\n","      <td>170.0</td>\n","      <td>9.0</td>\n","      <td>0.0</td>\n","      <td>137.0</td>\n","      <td>136.0</td>\n","      <td>138.0</td>\n","      <td>11.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 22 columns</p>\n","</div>"],"text/plain":["   baseline value  accelerations  fetal_movement  uterine_contractions   \n","0           120.0          0.000             0.0                 0.000  \\\n","1           132.0          0.006             0.0                 0.006   \n","2           133.0          0.003             0.0                 0.008   \n","3           134.0          0.003             0.0                 0.008   \n","4           132.0          0.007             0.0                 0.008   \n","\n","   light_decelerations  severe_decelerations  prolongued_decelerations   \n","0                0.000                   0.0                       0.0  \\\n","1                0.003                   0.0                       0.0   \n","2                0.003                   0.0                       0.0   \n","3                0.003                   0.0                       0.0   \n","4                0.000                   0.0                       0.0   \n","\n","   abnormal_short_term_variability  mean_value_of_short_term_variability   \n","0                             73.0                                   0.5  \\\n","1                             17.0                                   2.1   \n","2                             16.0                                   2.1   \n","3                             16.0                                   2.4   \n","4                             16.0                                   2.4   \n","\n","   percentage_of_time_with_abnormal_long_term_variability  ...  histogram_min   \n","0                                               43.0       ...           62.0  \\\n","1                                                0.0       ...           68.0   \n","2                                                0.0       ...           68.0   \n","3                                                0.0       ...           53.0   \n","4                                                0.0       ...           53.0   \n","\n","   histogram_max  histogram_number_of_peaks  histogram_number_of_zeroes   \n","0          126.0                        2.0                         0.0  \\\n","1          198.0                        6.0                         1.0   \n","2          198.0                        5.0                         1.0   \n","3          170.0                       11.0                         0.0   \n","4          170.0                        9.0                         0.0   \n","\n","   histogram_mode  histogram_mean  histogram_median  histogram_variance   \n","0           120.0           137.0             121.0                73.0  \\\n","1           141.0           136.0             140.0                12.0   \n","2           141.0           135.0             138.0                13.0   \n","3           137.0           134.0             137.0                13.0   \n","4           137.0           136.0             138.0                11.0   \n","\n","   histogram_tendency  fetal_health  \n","0                 1.0           2.0  \n","1                 0.0           1.0  \n","2                 0.0           1.0  \n","3                 1.0           1.0  \n","4                 1.0           1.0  \n","\n","[5 rows x 22 columns]"]},"metadata":{}}]},{"cell_type":"markdown","source":"## EDA ","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{},"execution_count":3,"outputs":[{"name":"stdout","output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\n\nRangeIndex: 2126 entries, 0 to 2125\n\nData columns (total 22 columns):\n\n #   Column                                                  Non-Null Count  Dtype  \n\n---  ------                                                  --------------  -----  \n\n 0   baseline value                                          2126 non-null   float64\n\n 1   accelerations                                           2126 non-null   float64\n\n 2   fetal_movement                                          2126 non-null   float64\n\n 3   uterine_contractions                                    2126 non-null   float64\n\n 4   light_decelerations                                     2126 non-null   float64\n\n 5   severe_decelerations                                    2126 non-null   float64\n\n 6   prolongued_decelerations                                2126 non-null   float64\n\n 7   abnormal_short_term_variability                         2126 non-null   float64\n\n 8   mean_value_of_short_term_variability                    2126 non-null   float64\n\n 9   percentage_of_time_with_abnormal_long_term_variability  2126 non-null   float64\n\n 10  mean_value_of_long_term_variability                     2126 non-null   float64\n\n 11  histogram_width                                         2126 non-null   float64\n\n 12  histogram_min                                           2126 non-null   float64\n\n 13  histogram_max                                           2126 non-null   float64\n\n 14  histogram_number_of_peaks                               2126 non-null   float64\n\n 15  histogram_number_of_zeroes                              2126 non-null   float64\n\n 16  histogram_mode                                          2126 non-null   float64\n\n 17  histogram_mean                                          2126 non-null   float64\n\n 18  histogram_median                                        2126 non-null   float64\n\n 19  histogram_variance                                      2126 non-null   float64\n\n 20  histogram_tendency                                      2126 non-null   float64\n\n 21  fetal_health                                            2126 non-null   float64\n\ndtypes: float64(22)\n\nmemory usage: 365.5 KB\n"}]},{"cell_type":"markdown","source":"*Checking for null values*","metadata":{}},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"scrolled":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":["baseline value                                            0\n","accelerations                                             0\n","fetal_movement                                            0\n","uterine_contractions                                      0\n","light_decelerations                                       0\n","severe_decelerations                                      0\n","prolongued_decelerations                                  0\n","abnormal_short_term_variability                           0\n","mean_value_of_short_term_variability                      0\n","percentage_of_time_with_abnormal_long_term_variability    0\n","mean_value_of_long_term_variability                       0\n","histogram_width                                           0\n","histogram_min                                             0\n","histogram_max                                             0\n","histogram_number_of_peaks                                 0\n","histogram_number_of_zeroes                                0\n","histogram_mode                                            0\n","histogram_mean                                            0\n","histogram_median                                          0\n","histogram_variance                                        0\n","histogram_tendency                                        0\n","fetal_health                                              0\n","dtype: int64"]},"metadata":{}}]},{"cell_type":"markdown","source":"*Removing Duplicates*","metadata":{}},{"cell_type":"code","source":"df.duplicated().sum()","metadata":{},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":["13"]},"metadata":{}}]},{"cell_type":"code","source":"df=df.drop_duplicates()","metadata":{},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"*Exploring The distribution of the data*","metadata":{}},{"cell_type":"code","source":"df.shape","metadata":{},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":["(2113, 22)"]},"metadata":{}}]},{"cell_type":"markdown","source":"- # **AutoML**","metadata":{}},{"cell_type":"markdown","source":"## What is AutoML?","metadata":{}},{"cell_type":"markdown","source":"- **Automated Machine Learning (AutoML)** is the process of automating machine learning workflows. In an ideal situation, we, as the users, only need to provide a dataset. The AutoML tool should automatically produce good-performing model pipelines for us.","metadata":{}},{"cell_type":"code","source":"from IPython.display import Image\n\nImage(url='https://sp-ao.shortpixel.ai/client/to_webp,q_glossy,ret_img,w_622/https://www.justintodata.com/wp-content/uploads/2022/03/image-1.png')","metadata":{},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/html":["<img src=\"https://sp-ao.shortpixel.ai/client/to_webp,q_glossy,ret_img,w_622/https://www.justintodata.com/wp-content/uploads/2022/03/image-1.png\"/>"],"text/plain":["<IPython.core.display.Image object>"]},"metadata":{}}]},{"cell_type":"markdown","source":"So AutoML should handle tasks like:\n- data preprocessing\n- algorithm selection\n- hyperparameter tuning\n- model training","metadata":{}},{"cell_type":"markdown","source":"## EvalML","metadata":{}},{"cell_type":"code","source":"x = df.drop([\"fetal_health\"] , axis = 1)\ny = df[\"fetal_health\"].values\nx_train , x_test , y_train ,y_test = train_test_split(x,y , test_size= 0.25 , random_state= 42)","metadata":{},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"## Loading The Dataset","metadata":{}},{"cell_type":"code","source":"import evalml","metadata":{},"execution_count":27,"outputs":[{"name":"stderr","output_type":"stream","text":"Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n"}]},{"cell_type":"code","source":"x_train,x_test, y_train, y_test= evalml.preprocessing.split_data(x,y,problem_type ='MULTICLASS')","metadata":{},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"x_train.head()","metadata":{},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>baseline value</th>\n","      <th>accelerations</th>\n","      <th>fetal_movement</th>\n","      <th>uterine_contractions</th>\n","      <th>light_decelerations</th>\n","      <th>severe_decelerations</th>\n","      <th>prolongued_decelerations</th>\n","      <th>abnormal_short_term_variability</th>\n","      <th>mean_value_of_short_term_variability</th>\n","      <th>percentage_of_time_with_abnormal_long_term_variability</th>\n","      <th>...</th>\n","      <th>histogram_width</th>\n","      <th>histogram_min</th>\n","      <th>histogram_max</th>\n","      <th>histogram_number_of_peaks</th>\n","      <th>histogram_number_of_zeroes</th>\n","      <th>histogram_mode</th>\n","      <th>histogram_mean</th>\n","      <th>histogram_median</th>\n","      <th>histogram_variance</th>\n","      <th>histogram_tendency</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>560</th>\n","      <td>130.0</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","      <td>0.007</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>37.0</td>\n","      <td>1.8</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>90.0</td>\n","      <td>58.0</td>\n","      <td>148.0</td>\n","      <td>4.0</td>\n","      <td>1.0</td>\n","      <td>127.0</td>\n","      <td>121.0</td>\n","      <td>126.0</td>\n","      <td>21.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1482</th>\n","      <td>132.0</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","      <td>0.007</td>\n","      <td>0.001</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>47.0</td>\n","      <td>0.7</td>\n","      <td>1.0</td>\n","      <td>...</td>\n","      <td>31.0</td>\n","      <td>114.0</td>\n","      <td>145.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>136.0</td>\n","      <td>134.0</td>\n","      <td>136.0</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2074</th>\n","      <td>130.0</td>\n","      <td>0.008</td>\n","      <td>0.001</td>\n","      <td>0.005</td>\n","      <td>0.000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>70.0</td>\n","      <td>0.7</td>\n","      <td>6.0</td>\n","      <td>...</td>\n","      <td>31.0</td>\n","      <td>127.0</td>\n","      <td>158.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>139.0</td>\n","      <td>140.0</td>\n","      <td>141.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>953</th>\n","      <td>136.0</td>\n","      <td>0.005</td>\n","      <td>0.000</td>\n","      <td>0.003</td>\n","      <td>0.004</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>37.0</td>\n","      <td>1.2</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>94.0</td>\n","      <td>64.0</td>\n","      <td>158.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>139.0</td>\n","      <td>137.0</td>\n","      <td>141.0</td>\n","      <td>21.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>812</th>\n","      <td>146.0</td>\n","      <td>0.003</td>\n","      <td>0.000</td>\n","      <td>0.004</td>\n","      <td>0.002</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>38.0</td>\n","      <td>1.2</td>\n","      <td>33.0</td>\n","      <td>...</td>\n","      <td>78.0</td>\n","      <td>94.0</td>\n","      <td>172.0</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>162.0</td>\n","      <td>154.0</td>\n","      <td>158.0</td>\n","      <td>19.0</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 21 columns</p>\n","</div>"],"text/plain":["      baseline value  accelerations  fetal_movement  uterine_contractions   \n","560            130.0          0.000           0.000                 0.000  \\\n","1482           132.0          0.000           0.000                 0.007   \n","2074           130.0          0.008           0.001                 0.005   \n","953            136.0          0.005           0.000                 0.003   \n","812            146.0          0.003           0.000                 0.004   \n","\n","      light_decelerations  severe_decelerations  prolongued_decelerations   \n","560                 0.007                   0.0                       0.0  \\\n","1482                0.001                   0.0                       0.0   \n","2074                0.000                   0.0                       0.0   \n","953                 0.004                   0.0                       0.0   \n","812                 0.002                   0.0                       0.0   \n","\n","      abnormal_short_term_variability  mean_value_of_short_term_variability   \n","560                              37.0                                   1.8  \\\n","1482                             47.0                                   0.7   \n","2074                             70.0                                   0.7   \n","953                              37.0                                   1.2   \n","812                              38.0                                   1.2   \n","\n","      percentage_of_time_with_abnormal_long_term_variability  ...   \n","560                                                 0.0       ...  \\\n","1482                                                1.0       ...   \n","2074                                                6.0       ...   \n","953                                                 0.0       ...   \n","812                                                33.0       ...   \n","\n","      histogram_width  histogram_min  histogram_max   \n","560              90.0           58.0          148.0  \\\n","1482             31.0          114.0          145.0   \n","2074             31.0          127.0          158.0   \n","953              94.0           64.0          158.0   \n","812              78.0           94.0          172.0   \n","\n","      histogram_number_of_peaks  histogram_number_of_zeroes  histogram_mode   \n","560                         4.0                         1.0           127.0  \\\n","1482                        1.0                         0.0           136.0   \n","2074                        1.0                         0.0           139.0   \n","953                         2.0                         0.0           139.0   \n","812                         2.0                         3.0           162.0   \n","\n","      histogram_mean  histogram_median  histogram_variance  histogram_tendency  \n","560            121.0             126.0                21.0                 1.0  \n","1482           134.0             136.0                 2.0                 1.0  \n","2074           140.0             141.0                 3.0                 0.0  \n","953            137.0             141.0                21.0                 1.0  \n","812            154.0             158.0                19.0                 1.0  \n","\n","[5 rows x 21 columns]"]},"metadata":{}}]},{"cell_type":"code","source":"from evalml.automl import AutoMLSearch\nautoml= AutoMLSearch(X_train= x_train , y_train= y_train, problem_type='multiclass')\nautoml.search()","metadata":{},"execution_count":32,"outputs":[{"name":"stdout","output_type":"stream","text":"[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001459 seconds.\n\nYou can set `force_row_wise=true` to remove the overhead.\n\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\n[LightGBM] [Info] Total Bins 1216\n\n[LightGBM] [Info] Number of data points in the train set: 1315, number of used features: 11\n\n[LightGBM] [Info] Start training from score -0.405085\n\n[LightGBM] [Info] Start training from score -1.792520\n\n[LightGBM] [Info] Start training from score -1.792520\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000427 seconds.\n\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 1325\n\n[LightGBM] [Info] Number of data points in the train set: 1315, number of used features: 11\n\n[LightGBM] [Info] Start training from score -0.405085\n\n[LightGBM] [Info] Start training from score -1.792520\n\n[LightGBM] [Info] Start training from score -1.792520\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000419 seconds.\n\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 1214\n\n[LightGBM] [Info] Number of data points in the train set: 1316, number of used features: 11\n\n[LightGBM] [Info] Start training from score -0.404706\n\n[LightGBM] [Info] Start training from score -1.793280\n\n[LightGBM] [Info] Start training from score -1.793280\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"},{"name":"stderr","output_type":"stream","text":"The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n\nThe y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n\nThe y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n"},{"execution_count":32,"output_type":"execute_result","data":{"text/plain":["{1: {'Random Forest Classifier w/ Label Encoder + Imputer + Oversampler + RF Classifier Select From Model': 4.051091194152832,\n","  'Total time of batch': 4.205659627914429},\n"," 2: {'LightGBM Classifier w/ Label Encoder + Imputer + Oversampler + Select Columns Transformer': 3.3338782787323,\n","  'Extra Trees Classifier w/ Label Encoder + Imputer + Oversampler + Select Columns Transformer': 2.1740009784698486,\n","  'Elastic Net Classifier w/ Label Encoder + Imputer + Oversampler + Standard Scaler + Select Columns Transformer': 2.275012493133545,\n","  'XGBoost Classifier w/ Label Encoder + Imputer + Oversampler + Select Columns Transformer': 3.9371609687805176,\n","  'Logistic Regression Classifier w/ Label Encoder + Imputer + Oversampler + Standard Scaler + Select Columns Transformer': 5.867302179336548,\n","  'Total time of batch': 18.280128240585327}}"]},"metadata":{}}]},{"cell_type":"code","source":"automl.rankings","metadata":{},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>pipeline_name</th>\n","      <th>search_order</th>\n","      <th>ranking_score</th>\n","      <th>mean_cv_score</th>\n","      <th>standard_deviation_cv_score</th>\n","      <th>percent_better_than_baseline</th>\n","      <th>high_variance_cv</th>\n","      <th>parameters</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5</td>\n","      <td>XGBoost Classifier w/ Label Encoder + Imputer ...</td>\n","      <td>5</td>\n","      <td>0.175004</td>\n","      <td>0.175004</td>\n","      <td>0.011345</td>\n","      <td>97.806006</td>\n","      <td>False</td>\n","      <td>{'Label Encoder': {'positive_label': None}, 'I...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Random Forest Classifier w/ Label Encoder + Im...</td>\n","      <td>1</td>\n","      <td>0.221909</td>\n","      <td>0.221909</td>\n","      <td>0.027801</td>\n","      <td>97.217973</td>\n","      <td>False</td>\n","      <td>{'Label Encoder': {'positive_label': None}, 'I...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4</td>\n","      <td>Elastic Net Classifier w/ Label Encoder + Impu...</td>\n","      <td>4</td>\n","      <td>0.263180</td>\n","      <td>0.263180</td>\n","      <td>0.011976</td>\n","      <td>96.700571</td>\n","      <td>False</td>\n","      <td>{'Label Encoder': {'positive_label': None}, 'I...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>6</td>\n","      <td>Logistic Regression Classifier w/ Label Encode...</td>\n","      <td>6</td>\n","      <td>0.263415</td>\n","      <td>0.263415</td>\n","      <td>0.012138</td>\n","      <td>96.697616</td>\n","      <td>False</td>\n","      <td>{'Label Encoder': {'positive_label': None}, 'I...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2</td>\n","      <td>LightGBM Classifier w/ Label Encoder + Imputer...</td>\n","      <td>2</td>\n","      <td>0.265697</td>\n","      <td>0.265697</td>\n","      <td>0.017839</td>\n","      <td>96.669008</td>\n","      <td>False</td>\n","      <td>{'Label Encoder': {'positive_label': None}, 'I...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>3</td>\n","      <td>Extra Trees Classifier w/ Label Encoder + Impu...</td>\n","      <td>3</td>\n","      <td>0.319212</td>\n","      <td>0.319212</td>\n","      <td>0.004525</td>\n","      <td>95.998105</td>\n","      <td>False</td>\n","      <td>{'Label Encoder': {'positive_label': None}, 'I...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>Mode Baseline Multiclass Classification Pipeline</td>\n","      <td>0</td>\n","      <td>7.976517</td>\n","      <td>7.976517</td>\n","      <td>0.033623</td>\n","      <td>0.000000</td>\n","      <td>False</td>\n","      <td>{'Label Encoder': {'positive_label': None}, 'B...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id                                      pipeline_name  search_order   \n","0   5  XGBoost Classifier w/ Label Encoder + Imputer ...             5  \\\n","1   1  Random Forest Classifier w/ Label Encoder + Im...             1   \n","2   4  Elastic Net Classifier w/ Label Encoder + Impu...             4   \n","3   6  Logistic Regression Classifier w/ Label Encode...             6   \n","4   2  LightGBM Classifier w/ Label Encoder + Imputer...             2   \n","5   3  Extra Trees Classifier w/ Label Encoder + Impu...             3   \n","6   0   Mode Baseline Multiclass Classification Pipeline             0   \n","\n","   ranking_score  mean_cv_score  standard_deviation_cv_score   \n","0       0.175004       0.175004                     0.011345  \\\n","1       0.221909       0.221909                     0.027801   \n","2       0.263180       0.263180                     0.011976   \n","3       0.263415       0.263415                     0.012138   \n","4       0.265697       0.265697                     0.017839   \n","5       0.319212       0.319212                     0.004525   \n","6       7.976517       7.976517                     0.033623   \n","\n","   percent_better_than_baseline  high_variance_cv   \n","0                     97.806006             False  \\\n","1                     97.217973             False   \n","2                     96.700571             False   \n","3                     96.697616             False   \n","4                     96.669008             False   \n","5                     95.998105             False   \n","6                      0.000000             False   \n","\n","                                          parameters  \n","0  {'Label Encoder': {'positive_label': None}, 'I...  \n","1  {'Label Encoder': {'positive_label': None}, 'I...  \n","2  {'Label Encoder': {'positive_label': None}, 'I...  \n","3  {'Label Encoder': {'positive_label': None}, 'I...  \n","4  {'Label Encoder': {'positive_label': None}, 'I...  \n","5  {'Label Encoder': {'positive_label': None}, 'I...  \n","6  {'Label Encoder': {'positive_label': None}, 'B...  "]},"metadata":{}}]},{"cell_type":"code","source":"best_pipeline =automl.best_pipeline\nbest_pipeline","metadata":{},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":["pipeline = MulticlassClassificationPipeline(component_graph={'Label Encoder': ['Label Encoder', 'X', 'y'], 'Imputer': ['Imputer', 'X', 'Label Encoder.y'], 'Oversampler': ['Oversampler', 'Imputer.x', 'Label Encoder.y'], 'Select Columns Transformer': ['Select Columns Transformer', 'Oversampler.x', 'Oversampler.y'], 'XGBoost Classifier': ['XGBoost Classifier', 'Select Columns Transformer.x', 'Oversampler.y']}, parameters={'Label Encoder':{'positive_label': None}, 'Imputer':{'categorical_impute_strategy': 'most_frequent', 'numeric_impute_strategy': 'mean', 'boolean_impute_strategy': 'most_frequent', 'categorical_fill_value': None, 'numeric_fill_value': None, 'boolean_fill_value': None}, 'Oversampler':{'sampling_ratio': 0.25, 'k_neighbors_default': 5, 'n_jobs': -1, 'sampling_ratio_dict': None, 'k_neighbors': 5}, 'Select Columns Transformer':{'columns': ['baseline value', 'accelerations', 'prolongued_decelerations', 'abnormal_short_term_variability', 'mean_value_of_short_term_variability', 'percentage_of_time_with_abnormal_long_term_variability', 'mean_value_of_long_term_variability', 'histogram_mode', 'histogram_mean', 'histogram_median', 'histogram_variance']}, 'XGBoost Classifier':{'eta': 0.1, 'max_depth': 6, 'min_child_weight': 1, 'n_estimators': 100, 'n_jobs': -1, 'eval_metric': 'logloss'}}, random_seed=0)"]},"metadata":{}}]},{"cell_type":"code","source":"automl.describe_pipeline(automl.rankings.iloc[0]['id'])","metadata":{"scrolled":true},"execution_count":35,"outputs":[{"name":"stdout","output_type":"stream","text":"\n\n********************************************************************************************\n\n* XGBoost Classifier w/ Label Encoder + Imputer + Oversampler + Select Columns Transformer *\n\n********************************************************************************************\n\n\n\nProblem Type: multiclass\n\nModel Family: XGBoost\n\n\n\nPipeline Steps\n\n==============\n\n1. Label Encoder\n\n\t * positive_label : None\n\n2. Imputer\n\n\t * categorical_impute_strategy : most_frequent\n\n\t * numeric_impute_strategy : mean\n\n\t * boolean_impute_strategy : most_frequent\n\n\t * categorical_fill_value : None\n\n\t * numeric_fill_value : None\n\n\t * boolean_fill_value : None\n\n3. Oversampler\n\n\t * sampling_ratio : 0.25\n\n\t * k_neighbors_default : 5\n\n\t * n_jobs : -1\n\n\t * sampling_ratio_dict : None\n\n\t * k_neighbors : 5\n\n4. Select Columns Transformer\n\n\t * columns : ['baseline value', 'accelerations', 'prolongued_decelerations', 'abnormal_short_term_variability', 'mean_value_of_short_term_variability', 'percentage_of_time_with_abnormal_long_term_variability', 'mean_value_of_long_term_variability', 'histogram_mode', 'histogram_mean', 'histogram_median', 'histogram_variance']\n\n5. XGBoost Classifier\n\n\t * eta : 0.1\n\n\t * max_depth : 6\n\n\t * min_child_weight : 1\n\n\t * n_estimators : 100\n\n\t * n_jobs : -1\n\n\t * eval_metric : logloss\n\n\n\nTraining\n\n========\n\nTraining for multiclass problems.\n\nTotal training time (including CV): 3.9 seconds\n\n\n\nCross Validation\n\n----------------\n\n             Log Loss Multiclass  MCC Multiclass  AUC Weighted  AUC Macro  AUC Micro  Precision Weighted  Precision Macro  Precision Micro  F1 Weighted  F1 Macro  F1 Micro  Balanced Accuracy Multiclass  Accuracy Multiclass # Training # Validation\n\n0                          0.166           0.844         0.983      0.985      0.993               0.943            0.912            0.943        0.943     0.903     0.943                         0.894                0.943      1,126          564\n\n1                          0.188           0.796         0.979      0.982      0.992               0.925            0.897            0.927        0.925     0.882     0.927                         0.872                0.927      1,127          563\n\n2                          0.172           0.816         0.981      0.983      0.992               0.933            0.906            0.933        0.933     0.899     0.933                         0.892                0.933      1,127          563\n\nmean                       0.175           0.819         0.981      0.983      0.992               0.934            0.905            0.934        0.934     0.895     0.934                         0.886                0.934          -            -\n\nstd                        0.011           0.024         0.002      0.002      0.001               0.009            0.008            0.008        0.009     0.011     0.008                         0.013                0.008          -            -\n\ncoef of var                0.065           0.030         0.002      0.002      0.001               0.010            0.009            0.009        0.010     0.013     0.009                         0.014                0.009          -            -\n"}]},{"cell_type":"code","source":"best_pipeline.score(x_test,y_test, objectives = ['F1 Weighted','F1 Macro','F1 Micro','Accuracy Multiclass','Precision Weighted','Precision Macro','Precision Micro'])","metadata":{},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":["OrderedDict([('F1 Weighted', 0.9495118218522473),\n","             ('F1 Macro', 0.9143715143715143),\n","             ('F1 Micro', 0.950354609929078),\n","             ('Accuracy Multiclass', 0.950354609929078),\n","             ('Precision Weighted', 0.9492168489813744),\n","             ('Precision Macro', 0.9249869252122137),\n","             ('Precision Micro', 0.950354609929078)])"]},"metadata":{}}]},{"cell_type":"code","source":"from evalml.objectives import get_optimization_objectives\nfrom evalml.problem_types import ProblemTypes\nfor objective in get_optimization_objectives(ProblemTypes.MULTICLASS):\n    print(objective.name)","metadata":{"scrolled":true},"execution_count":37,"outputs":[{"name":"stdout","output_type":"stream","text":"MCC Multiclass\n\nLog Loss Multiclass\n\nAUC Weighted\n\nAUC Macro\n\nAUC Micro\n\nPrecision Weighted\n\nPrecision Macro\n\nPrecision Micro\n\nF1 Weighted\n\nF1 Macro\n\nF1 Micro\n\nBalanced Accuracy Multiclass\n\nAccuracy Multiclass\n"}]},{"cell_type":"code","source":"# if I want to tune my model based on f1 , recall , precision , etc..\nautoml_customized= AutoMLSearch(X_train= x_train, y_train = y_train,\n                               problem_type='multiclass',\n                               objective= 'F1 Weighted',\n                               additional_objectives=['F1 Macro','F1 Micro','Accuracy Multiclass','Precision Weighted','Precision Macro','Precision Micro'],\n                               max_batches=1,\n                               optimize_thresholds= True)\nautoml_customized.search()","metadata":{},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":["{1: {'Random Forest Classifier w/ Label Encoder + Imputer + Oversampler + RF Classifier Select From Model': 2.5808777809143066,\n","  'Total time of batch': 2.7113780975341797}}"]},"metadata":{}}]},{"cell_type":"code","source":"automl_customized.rankings","metadata":{},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>pipeline_name</th>\n","      <th>search_order</th>\n","      <th>ranking_score</th>\n","      <th>mean_cv_score</th>\n","      <th>standard_deviation_cv_score</th>\n","      <th>percent_better_than_baseline</th>\n","      <th>high_variance_cv</th>\n","      <th>parameters</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Random Forest Classifier w/ Label Encoder + Im...</td>\n","      <td>1</td>\n","      <td>0.923375</td>\n","      <td>0.923375</td>\n","      <td>0.009303</td>\n","      <td>24.156032</td>\n","      <td>False</td>\n","      <td>{'Label Encoder': {'positive_label': None}, 'I...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>Mode Baseline Multiclass Classification Pipeline</td>\n","      <td>0</td>\n","      <td>0.681815</td>\n","      <td>0.681815</td>\n","      <td>0.001276</td>\n","      <td>0.000000</td>\n","      <td>False</td>\n","      <td>{'Label Encoder': {'positive_label': None}, 'B...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id                                      pipeline_name  search_order   \n","0   1  Random Forest Classifier w/ Label Encoder + Im...             1  \\\n","1   0   Mode Baseline Multiclass Classification Pipeline             0   \n","\n","   ranking_score  mean_cv_score  standard_deviation_cv_score   \n","0       0.923375       0.923375                     0.009303  \\\n","1       0.681815       0.681815                     0.001276   \n","\n","   percent_better_than_baseline  high_variance_cv   \n","0                     24.156032             False  \\\n","1                      0.000000             False   \n","\n","                                          parameters  \n","0  {'Label Encoder': {'positive_label': None}, 'I...  \n","1  {'Label Encoder': {'positive_label': None}, 'B...  "]},"metadata":{}}]},{"cell_type":"code","source":"automl_customized.describe_pipeline(automl_customized.rankings.iloc[0]['id'])","metadata":{},"execution_count":40,"outputs":[{"name":"stdout","output_type":"stream","text":"\n\n*******************************************************************************************************\n\n* Random Forest Classifier w/ Label Encoder + Imputer + Oversampler + RF Classifier Select From Model *\n\n*******************************************************************************************************\n\n\n\nProblem Type: multiclass\n\nModel Family: Random Forest\n\n\n\nPipeline Steps\n\n==============\n\n1. Label Encoder\n\n\t * positive_label : None\n\n2. Imputer\n\n\t * categorical_impute_strategy : most_frequent\n\n\t * numeric_impute_strategy : mean\n\n\t * boolean_impute_strategy : most_frequent\n\n\t * categorical_fill_value : None\n\n\t * numeric_fill_value : None\n\n\t * boolean_fill_value : None\n\n3. Oversampler\n\n\t * sampling_ratio : 0.25\n\n\t * k_neighbors_default : 5\n\n\t * n_jobs : -1\n\n\t * sampling_ratio_dict : None\n\n\t * k_neighbors : 5\n\n4. RF Classifier Select From Model\n\n\t * number_features : None\n\n\t * n_estimators : 10\n\n\t * max_depth : None\n\n\t * percent_features : 0.5\n\n\t * threshold : median\n\n\t * n_jobs : -1\n\n5. Random Forest Classifier\n\n\t * n_estimators : 100\n\n\t * max_depth : 6\n\n\t * n_jobs : -1\n\n\n\nTraining\n\n========\n\nTraining for multiclass problems.\n\nTotal training time (including CV): 2.5 seconds\n\n\n\nCross Validation\n\n----------------\n\n             F1 Weighted  F1 Macro  F1 Micro  Accuracy Multiclass  Precision Weighted  Precision Macro  Precision Micro # Training # Validation\n\n0                  0.932     0.868     0.934                0.934               0.932            0.889            0.934      1,126          564\n\n1                  0.914     0.848     0.917                0.917               0.914            0.866            0.917      1,127          563\n\n2                  0.924     0.881     0.925                0.925               0.924            0.901            0.925      1,127          563\n\nmean               0.923     0.866     0.925                0.925               0.923            0.885            0.925          -            -\n\nstd                0.009     0.017     0.009                0.009               0.009            0.018            0.009          -            -\n\ncoef of var        0.010     0.019     0.010                0.010               0.010            0.020            0.010          -            -\n"}]}]}